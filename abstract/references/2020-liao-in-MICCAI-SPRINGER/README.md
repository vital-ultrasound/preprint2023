# 
## Citations
8
https://scholar.google.com/scholar?cites=6557094964354740203&as_sdt=2005&sciodt=0,5&hl=en
Retrived
Thu 28 Oct 17:06:21 BST 2021

## Authors 
liao
https://scholar.google.com/citations?user=HvWTE0IAAAAJ&hl=en&oi=sra

rohling
https://scholar.google.com/citations?user=_KwSTGIAAAAJ&hl=en&oi=sra


## Notes

*  "a cardiologist with 30 years clinical expe-
rience was given the task to assign the quality assessment and also the view
classification labels 1 for a total of 16,612 echo cine series from 3,157 unique
patients, each echo series containing 40-70 image frames "

* "The quality labels were defined in
four coarse quality categories: Poor (0% ∼ 25%), Fair (25% ∼ 50%), Good
(50% ∼ 75%), and Excellent (75% ∼ 100%), with the percentages reference to
the lowest to highest image qualities within each category."


* 
"Let us note the collected dataset as D = {x i , q i , v i } i=1 , where x i is a 2D echo
image, q i ∈ C = {c : Poor, . . . , Excellent} and v i ∈ {A2C, . . . , SUPRA} are the
corresponding image quality and view classification labels, and q i and v i are
vectors representing the one-hot version of respective label."





this work cite:

"UltraGAN: Ultrasound Enhancement Through Adversarial Generation"
https://scholar.google.com/scholar?cites=2598962098496148274&as_sdt=2005&sciodt=0,5&hl=en
https://github.com/BCV-Uniandes/UltraGAN  


## Links 
https://link.springer.com/chapter/10.1007/978-3-030-32245-8_76

## Bibtex 

```

@InProceedings{10.1007/978-3-030-32245-8_76,
author="Liao, Zhibin
and Jafari, Mohammad H.
and Girgis, Hany
and Gin, Kenneth
and Rohling, Robert
and Abolmaesumi, Purang
and Tsang, Teresa",
editor="Shen, Dinggang
and Liu, Tianming
and Peters, Terry M.
and Staib, Lawrence H.
and Essert, Caroline
and Zhou, Sean
and Yap, Pew-Thian
and Khan, Ali",
title="Echocardiography View Classification Using Quality Transfer Star Generative Adversarial Networks",
booktitle="Medical Image Computing and Computer Assisted Intervention -- MICCAI 2019",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="687--695",
abstract="2D echocardiography (echo) is the most widely used imaging technique to identify cardiac disease. In addition to anatomical variability in patients, the quality of acquired echo image can vary significantly depending on the ultrasound (US) machine and the experience level of the operator, where a poor image quality can affect the diagnosis. This variability can also result in reduced performance of machine learning models trained on these data. With the recent advances in generative adversarial networks (GAN), we demonstrate that it is possible to transfer the image quality of echo images to a user-defined quality level with the use of a multi-domain transfer approach referred as StarGAN. The proposed quality transfer StarGAN (QT-StarGAN) requires no pairs of low-and high-quality echo images and incorporates the temporal information of echo images during the training phase. We evaluate the proposed approach using 16,612 echo cine series obtained from 3,157 patients. Using a standard echo view classification task, we demonstrate that the accuracy of classification is significantly improved using QT-StarGAN.",
isbn="978-3-030-32245-8"
}
```

