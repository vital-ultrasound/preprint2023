# 
## Citations

1
https://scholar.google.com/scholar?cites=11677324437112667847&as_sdt=2005&sciodt=0,5&hl=en
Retrived
Thu 27 Jan 12:26:09 GMT 2022

## Authors 

Reynaud 
https://scholar.google.com/citations?user=jD0_c64AAAAJ&hl=en&oi=sra

Bernhard Kainz
https://scholar.google.com/citations?user=Igxq-YEAAAAJ&hl=en&oi=ao

Arian Beqiri
Ultromics 
https://scholar.google.com/citations?user=osD0r24AAAAJ&hl=en&oi=sra

## Notes

## Links 

https://link.springer.com/chapter/10.1007/978-3-030-87231-1_48#citeas
https://arxiv.org/pdf/2107.00977.pdf
https://github.com/HReynaud/UVT

## Bibtex 

```

@InProceedings{10.1007/978-3-030-87231-1_48,
author="Reynaud, Hadrien
and Vlontzos, Athanasios
and Hou, Benjamin
and Beqiri, Arian
and Leeson, Paul
and Kainz, Bernhard",
editor="de Bruijne, Marleen
and Cattin, Philippe C.
and Cotin, St{\'e}phane
and Padoy, Nicolas
and Speidel, Stefanie
and Zheng, Yefeng
and Essert, Caroline",
title="Ultrasound Video Transformers forÂ Cardiac Ejection Fraction Estimation",
booktitle="Medical Image Computing and Computer Assisted Intervention -- MICCAI 2021",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="495--505",
abstract="Cardiac ultrasound imaging is used to diagnose various heart diseases. Common analysis pipelines involve manual processing of the video frames by expert clinicians. This suffers from intra- and inter-observer variability. We propose a novel approach to ultrasound video analysis using a transformer architecture based on a Residual Auto-Encoder Network and a BERT model adapted for token classification. This enables videos of any length to be processed. We apply our model to the task of End-Systolic (ES) and End-Diastolic (ED) frame detection and the automated computation of the left ventricular ejection fraction. We achieve an average frame distance of 3.36 frames for the ES and 7.17 frames for the ED on videos of arbitrary length. Our end-to-end learnable approach can estimate the ejection fraction with a MAE of 5.95 and {\$}{\$}R^2{\$}{\$}R2of 0.52 in 0.15 s per video, showing that segmentation is not the only way to predict ejection fraction. Code and models are available at https://github.com/HReynaud/UVT.",
isbn="978-3-030-87231-1"
}
```

