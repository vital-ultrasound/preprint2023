# 
## Citations
1 Retrived Thu 26 May 16:01:18 BST 2022   
1 on Tue 21 Jun 00:04:37 BST 2022

https://scholar.google.com/scholar?cluster=2057480374976468640&hl=en&as_sdt=2005&sciodt=0,5

## Authors 

## Notes

## Links 

## Bibtex 

```
@article{WU2022102397,
title = {Semi-supervised segmentation of echocardiography videos via noise-resilient spatiotemporal semantic calibration and fusion},
journal = {Medical Image Analysis},
volume = {78},
pages = {102397},
year = {2022},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2022.102397},
url = {https://www.sciencedirect.com/science/article/pii/S1361841522000494},
author = {Huisi Wu and Jiasheng Liu and Fangyan Xiao and Zhenkun Wen and Lan Cheng and Jing Qin},
keywords = {Echocardiography, Video semantic segmentation, Deep learning, Temporal context extraction, Spatiotemporal semantic calibration, Spatiotemporal semantic fusion},
abstract = {We present a novel model for left ventricle endocardium segmentation from echocardiography video, which is of great significance in clinical practice and yet a challenging task due to (1) the severe speckle noise in echocardiography videos, (2) the irregular motion of pathological heart, and (3) the limited training data caused by high annotation cost. The proposed model has three compelling characteristics. First, we propose a novel adaptive spatiotemporal semantic calibration method to align the feature maps of consecutive frames, where the spatiotemporal correspondences are figured out based on feature maps instead of pixels, thereby mitigating the adverse effects of speckle noise in the calibration. Second, we further learn the importance of each feature map of neighbouring frames to the current frame from the temporal perspective so as to distinctively rather than uniformly harness the temporal information to tackle the irregular and anisotropic motions. Third, we integrate these techniques into the mean teacher semi-supervised architecture to leverage a large amount of unlabeled data to improve the segmentation accuracy. We extensively evaluate the proposed method on two public echocardiography video datasets (EchoNet-Dynamic and CAMUS), where the average dice coefficient on the left ventricular endocardium segmentation achieves 92.87% and 93.79%, respectively. Comparisons with state-of-the-art methods also demonstrate the effectiveness of the proposed method by achieving a better segmentation performance with a faster speed.}
}



```

