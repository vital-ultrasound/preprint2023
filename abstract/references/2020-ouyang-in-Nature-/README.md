# 
## Citations

120
https://scholar.google.com/scholar?cites=17275521952979726648&as_sdt=2005&sciodt=0,5&hl=en
Retrived
Fri  7 Jan 10:34:53 GMT 2022

## Authors 

## Notes

"

Spatiotemporal convolutions that incorporate spatial information in two dimensions and temporal information in the third dimension, have been used in non-medical video-clasification task 29, 30. 

29
A Closer Look at Spatiotemporal Convolutions for Action Recognition
Du Tran, Heng Wang, Lorenzo Torresani, Jamie Ray, Yann LeCun, Manohar Paluri; Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018, pp. 6450-6459 
https://openaccess.thecvf.com/content_cvpr_2018/html/Tran_A_Closer_Look_CVPR_2018_paper.html
https://scholar.google.com/scholar?cites=9524036545693727210&as_sdt=2005&sciodt=0,5&hl=en

30
Learning Spatiotemporal Features With 3D Convolutional Networks
Du Tran, Lubomir Bourdev, Rob Fergus, Lorenzo Torresani, Manohar Paluri; Proceedings of the IEEE International Conference on Computer Vision (ICCV), 2015, pp. 4489-4497 
https://openaccess.thecvf.com/content_iccv_2015/html/Tran_Learning_Spatiotemporal_Features_ICCV_2015_paper.html
https://scholar.google.com/scholar?cites=6546377120299846276&as_sdt=2005&sciodt=0,5&hl=en

"



## Links 

https://github.com/echonet/dynamic

https://echonet.github.io/dynamic/index.html

https://www.nature.com/articles/s41586-020-2145-8

## Bibtex 

```


@Article{Ouyang2020,
author={Ouyang, David
and He, Bryan
and Ghorbani, Amirata
and Yuan, Neal
and Ebinger, Joseph
and Langlotz, Curtis P.
and Heidenreich, Paul A.
and Harrington, Robert A.
and Liang, David H.
and Ashley, Euan A.
and Zou, James Y.},
title={Video-based AI for beat-to-beat assessment of cardiac function},
journal={Nature},
year={2020},
month={Apr},
day={01},
volume={580},
number={7802},
pages={252-256},
abstract={Accurate assessment of cardiac function is crucial for the diagnosis of cardiovascular disease1, screening for cardiotoxicity2 and decisions regarding the clinical management of patients with a critical illness3. However, human assessment of cardiac function focuses on a limited sampling of cardiac cycles and has considerable inter-observer variability despite years of training4,5. Here, to overcome this challenge, we present a video-based deep learning algorithm---EchoNet-Dynamic---that surpasses the performance of human experts in the critical tasks of segmenting the left ventricle, estimating ejection fraction and assessing cardiomyopathy. Trained on echocardiogram videos, our model accurately segments the left ventricle with a Dice similarity coefficient of 0.92, predicts ejection fraction with a mean absolute error of 4.1{\%} and reliably classifies heart failure with reduced ejection fraction (area under the curve of 0.97). In an external dataset from another healthcare system, EchoNet-Dynamic predicts the ejection fraction with a mean absolute error of 6.0{\%} and classifies heart failure with reduced ejection fraction with an area under the curve of 0.96. Prospective evaluation with repeated human measurements confirms that the model has variance that is comparable to or less than that of human experts. By leveraging information across multiple cardiac cycles, our model can rapidly identify subtle changes in ejection fraction, is more reproducible than human evaluation and lays the foundation for precise diagnosis of cardiovascular disease in real time. As a resource to promote further innovation, we also make publicly available a large dataset of 10,030 annotated echocardiogram videos.},
issn={1476-4687},
doi={10.1038/s41586-020-2145-8},
url={https://doi.org/10.1038/s41586-020-2145-8}
}

```

