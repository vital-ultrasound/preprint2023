# 
## Citations
11
https://scholar.google.com/scholar?cites=2993639487603654399&as_sdt=2005&sciodt=0,5&hl=en
Retrived
Fri 17 Sep 08:25:01 BST 2021

## Authors 

## Notes

## Links 
https://www.mdpi.com/2218-273X/10/5/665
## Bibtex 

```

@Article{biom10050665,
AUTHOR = {Kusunose, Kenya and Haga, Akihiro and Inoue, Mizuki and Fukuda, Daiju and Yamada, Hirotsugu and Sata, Masataka},
TITLE = {Clinically Feasible and Accurate View Classification of Echocardiographic Images Using Deep Learning},
JOURNAL = {Biomolecules},
VOLUME = {10},
YEAR = {2020},
NUMBER = {5},
ARTICLE-NUMBER = {665},
URL = {https://www.mdpi.com/2218-273X/10/5/665},
PubMedID = {32344829},
ISSN = {2218-273X},
ABSTRACT = {A proper echocardiographic study requires several video clips recorded from different acquisition angles for observation of the complex cardiac anatomy. However, these video clips are not necessarily labeled in a database. Identification of the acquired view becomes the first step of analyzing an echocardiogram. Currently, there is no consensus whether the mislabeled samples can be used to create a feasible clinical prediction model of ejection fraction (EF). The aim of this study was to test two types of input methods for the classification of images, and to test the accuracy of the prediction model for EF in a learning database containing mislabeled images that were not checked by observers. We enrolled 340 patients with five standard views (long axis, short axis, 3-chamber view, 4-chamber view and 2-chamber view) and 10 images in a cycle, used for training a convolutional neural network to classify views (total 17,000 labeled images). All DICOM images were rigidly registered and rescaled into a reference image to fit the size of echocardiographic images. We employed 5-fold cross validation to examine model performance. We tested models trained by two types of data, averaged images and 10 selected images. Our best model (from 10 selected images) classified video views with 98.1% overall test accuracy in the independent cohort. In our view classification model, 1.9% of the images were mislabeled. To determine if this 98.1% accuracy was acceptable for creating the clinical prediction model using echocardiographic data, we tested the prediction model for EF using learning data with a 1.9% error rate. The accuracy of the prediction model for EF was warranted, even with training data containing 1.9% mislabeled images. The CNN algorithm can classify images into five standard views in a clinical setting. Our results suggest that this approach may provide a clinically feasible accuracy level of view classification for the analysis of echocardiographic data.},
DOI = {10.3390/biom10050665}
}





```

